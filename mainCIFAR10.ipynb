{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from torchvision.transforms import *\n",
    "\n",
    "data = torchvision.datasets.CIFAR10(\".\", download=True, train=True)\n",
    "ds_label: str = \"CIFAR\"\n",
    "mean = (data.data / 255).mean()\n",
    "std = (data.data / 255).std()\n",
    "data.transform = Compose([Lambda(lambda x: x.convert('L')), ToTensor(), Normalize([mean], [std], True)])\n",
    "\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(30, 60, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(60, 120, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(3*3*120, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.relu(f.max_pool2d(self.conv1(x), 2))\n",
    "        x = f.relu(f.max_pool2d(self.conv2(x), 2))\n",
    "        x = f.relu(self.conv3(x))\n",
    "        x = x.view(-1,3*3*120)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return f.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "batch_size: int = 64\n",
    "epoch: int = 40\n",
    "lr: float = 0.01\n",
    "test_split: float = 0.2\n",
    "\n",
    "random_seed: int = 10\n",
    "shuffle_dataset: bool = True\n",
    "\n",
    "\n",
    "dataset_size: int = len(data)\n",
    "indices: list = list(range(dataset_size))\n",
    "split: int = int(np.floor(test_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler: SubsetRandomSampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler: SubsetRandomSampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader: DataLoader = DataLoader(data, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader: DataLoader = DataLoader(data, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "model: Network = Network().cuda()\n",
    "\n",
    "optimizer: SGD = SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy on epoch 0: 0.2215\n",
      "\n",
      "Test accuracy on epoch 1: 0.2718\n",
      "\n",
      "Test accuracy on epoch 2: 0.3632\n",
      "\n",
      "Test accuracy on epoch 3: 0.405\n",
      "\n",
      "Test accuracy on epoch 4: 0.4433\n",
      "\n",
      "Test accuracy on epoch 5: 0.4603\n",
      "\n",
      "Test accuracy on epoch 6: 0.4623\n",
      "\n",
      "Test accuracy on epoch 7: 0.502\n",
      "\n",
      "Test accuracy on epoch 8: 0.5119\n",
      "\n",
      "Test accuracy on epoch 9: 0.5298\n",
      "\n",
      "Test accuracy on epoch 10: 0.5542\n",
      "\n",
      "Test accuracy on epoch 11: 0.5483\n",
      "\n",
      "Test accuracy on epoch 12: 0.5723\n",
      "\n",
      "Test accuracy on epoch 13: 0.5962\n",
      "\n",
      "Test accuracy on epoch 14: 0.6005\n",
      "\n",
      "Test accuracy on epoch 15: 0.5974\n",
      "\n",
      "Test accuracy on epoch 16: 0.6115\n",
      "\n",
      "Test accuracy on epoch 17: 0.6232\n",
      "\n",
      "Test accuracy on epoch 18: 0.6122\n",
      "\n",
      "Test accuracy on epoch 19: 0.6423\n",
      "\n",
      "Test accuracy on epoch 20: 0.6544\n",
      "\n",
      "Test accuracy on epoch 21: 0.6589\n",
      "\n",
      "Test accuracy on epoch 22: 0.6484\n",
      "\n",
      "Test accuracy on epoch 23: 0.6604\n",
      "\n",
      "Test accuracy on epoch 24: 0.6591\n",
      "\n",
      "Test accuracy on epoch 25: 0.6716\n",
      "\n",
      "Test accuracy on epoch 26: 0.6746\n",
      "\n",
      "Test accuracy on epoch 27: 0.6801\n",
      "\n",
      "Test accuracy on epoch 28: 0.6688\n",
      "\n",
      "Test accuracy on epoch 29: 0.6766\n",
      "\n",
      "Test accuracy on epoch 30: 0.6779\n",
      "\n",
      "Test accuracy on epoch 31: 0.6763\n",
      "\n",
      "Test accuracy on epoch 32: 0.6889\n",
      "\n",
      "Test accuracy on epoch 33: 0.6888\n",
      "\n",
      "Test accuracy on epoch 34: 0.6843\n",
      "\n",
      "Test accuracy on epoch 35: 0.6767\n",
      "\n",
      "Test accuracy on epoch 36: 0.6846\n",
      "\n",
      "Test accuracy on epoch 37: 0.6815\n",
      "\n",
      "Test accuracy on epoch 38: 0.6734\n",
      "\n",
      "Test accuracy on epoch 39: 0.6819\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        result: torch.Tensor = model(x.cuda())\n",
    "        loss: torch.Tensor = f.cross_entropy(result, y.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct: int = 0\n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            output: torch.Tensor = model(x.cuda())\n",
    "            correct += torch.sum(output.data.max(1)[1] == y.cuda()).item()\n",
    "    print(f\"\\nTest accuracy on epoch {e}: {correct / split}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'model{}.pth'.format(ds_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageDraw, Image\n",
    "import random\n",
    "new_data = torchvision.datasets.CIFAR10(\".\", download=True, train=False, transform=None)\n",
    "new_data_loader: DataLoader = DataLoader(new_data, 1)\n",
    "file = open('labels{}.csv'.format(ds_label), 'w')\n",
    "for i, data in enumerate(new_data):\n",
    "    random_x, random_y = random.randint(0,18), random.randint(0,18)\n",
    "    img: Image.Image = data[0].copy()\n",
    "    img_draw: ImageDraw.ImageDraw = ImageDraw.Draw(img)\n",
    "    img_draw.rectangle([random_x, random_y, random_x + 13, random_y + 13], fill=0)\n",
    "    img.convert('L').save('{}/img/{}.jpg'.format(ds_label, i))\n",
    "    file.write('{},{},{},{}\\n'.format(i, data[1], random_x, random_y))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.transforms.functional import *\n",
    "images: list = list()\n",
    "train_images_ae: list = list()\n",
    "test_images_ae: list = list()\n",
    "train_images_misgan: list = list()\n",
    "test_images_misgan: list = list()\n",
    "for i in range(10_000):\n",
    "    img: Image = Image.open('{}/img/{}.jpg'.format(ds_label, i))\n",
    "    images.append(normalize(to_tensor(img), [mean], [std]))\n",
    "for i in range(8_000):\n",
    "    img: Image = Image.open('{}/imgAEtrain/{}.jpg'.format(ds_label, i))\n",
    "    train_images_ae.append(normalize(to_tensor(img), [mean], [std]))\n",
    "for i in range(2_000):\n",
    "    img: Image = Image.open('{}/imgAEtest/{}.jpg'.format(ds_label, i + 8000))\n",
    "    test_images_ae.append(normalize(to_tensor(img), [mean], [std]))\n",
    "for i in range(8_000):\n",
    "    img: Image = Image.open('{}/imgMISGANtrain/{}.jpg'.format(ds_label, i))\n",
    "    train_images_misgan.append(normalize(to_tensor(img), [mean], [std]))\n",
    "for i in range(2_000):\n",
    "    img: Image = Image.open('{}/imgMISGANtest/{}.jpg'.format(ds_label, i + 8000))\n",
    "    test_images_misgan.append(normalize(to_tensor(img), [mean], [std]))\n",
    "labels: list = list()\n",
    "labels_file = open('labels{}.csv'.format(ds_label), 'r')\n",
    "for i, line in enumerate(labels_file):\n",
    "    labels.append(int(line.split(',')[1]))\n",
    "dataset: TensorDataset = TensorDataset(torch.stack(images), torch.LongTensor(labels))\n",
    "data_loader: DataLoader = DataLoader(dataset, batch_size)\n",
    "train_loader_ae: DataLoader = DataLoader(TensorDataset(torch.stack(train_images_ae), torch.LongTensor(labels[:8000])), batch_size)\n",
    "test_loader_ae: DataLoader = DataLoader(TensorDataset(torch.stack(test_images_ae), torch.LongTensor(labels[8000:])), batch_size)\n",
    "train_loader_misgan: DataLoader = DataLoader(TensorDataset(torch.stack(train_images_misgan), torch.LongTensor(labels[:8000])), batch_size)\n",
    "test_loader_misgan: DataLoader = DataLoader(TensorDataset(torch.stack(test_images_misgan), torch.LongTensor(labels[8000:])), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy 0.293\n",
      "\n",
      "Accuracy 0.176\n",
      "\n",
      "Accuracy 0.1715\n",
      "\n",
      "Accuracy 0.501625\n",
      "\n",
      "Accuracy 0.458\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model.load_state_dict(torch.load('model{}.pth'.format(ds_label)))\n",
    "model.eval()\n",
    "def show_accuracy(data_loader, size):\n",
    "    correct: int = 0\n",
    "    for i, (x, y) in enumerate(data_loader):\n",
    "        output: torch.Tensor = model(x)\n",
    "        correct += torch.sum(output.data.max(1)[1] == y).item()\n",
    "#         if i == 0:\n",
    "#             print(output.data.max(1)[1])\n",
    "#             print(y)\n",
    "    print(f\"\\nAccuracy {correct / size}\")\n",
    "show_accuracy(data_loader, 10_000)\n",
    "show_accuracy(train_loader_ae, 8_000)\n",
    "show_accuracy(test_loader_ae, 2_000)\n",
    "show_accuracy(train_loader_misgan, 8_000)\n",
    "show_accuracy(test_loader_misgan, 2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_mask(x, y, size):\n",
    "    return np.concatenate([32 * i + np.arange(x, x + size) for i in\n",
    "                           np.arange(y, y + size)], axis=0).astype(np.int32)\n",
    "\n",
    "\n",
    "def data_with_defined_mask(x, mask):\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, generate_mask(mask[i][0], mask[i][1], 12)] = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "images = list()\n",
    "for i in range(10_000):\n",
    "    img: Image = Image.open('{}/img/{}.jpg'.format(ds_label,i))\n",
    "    images.append(np.array(img))\n",
    "images = np.array(images)\n",
    "masks = list()\n",
    "labels_file = open('labels{}.csv'.format(ds_label), 'r')\n",
    "for line in labels_file:\n",
    "    line_list: list = line.split(',')\n",
    "    masks.append((int(line_list[2]), int(line_list[3])))\n",
    "\n",
    "x, y = images / 255.0, labels\n",
    "\n",
    "data_train = x.reshape(-1, 32 * 32)\n",
    "\n",
    "data_train = data_with_defined_mask(data_train, masks)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data_mean = imp.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy 0.2938\n"
     ]
    }
   ],
   "source": [
    "data_mean_tensor = list()\n",
    "for img in data_mean:\n",
    "    data_mean_tensor.append(normalize(to_tensor(img.reshape(32, 32)).float(), [mean], [std]))\n",
    "data_mean_loader: DataLoader = DataLoader(TensorDataset(torch.stack(data_mean_tensor), torch.LongTensor(labels)), batch_size)\n",
    "show_accuracy(data_mean_loader, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
